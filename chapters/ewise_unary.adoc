//
// This confidential and proprietary software may be used only as
// authorised by a licensing agreement from ARM Limited
// (C) COPYRIGHT 2020-2021 ARM Limited
// ALL RIGHTS RESERVED
// The entire notice above must be reproduced on all authorised
// copies and copies may only be made to the extent permitted
// by a licensing agreement from ARM Limited.

=== Elementwise Unary Operators

==== ABS

Elementwise absolute value operation

*Arguments:*

|===
|Argument|Type|Name|Shape|Description

|Input|in_t*|input1|shape|Input tensor
|Output|in_t*|output|shape|Output tensor of same type, size as the input tensor
|===

*Operation Function:*

[source,c]
----
for_each (index in shape) {
    in_t value1 = tensor_read<in_t>(input1, shape, index)
    if (value1 < 0)
        value1 = apply_sub<in_t>(0, value1)
    tensor_write<in_t>(output, shape, index, value1)
}
----

*Supported Data Types:*

|===
|Profile|Mode|in_t|out_t

|Any|signed 32|int32
|MI, MT|float|float
|===

==== BITWISE_NOT

Elementwise bitwise NOT of input tensor.

*Arguments:*

|===
|Argument|Type|Name|Shape|Description

|Input|in_t*|input1|shape|Input tensor
|Output|in_t*|output|shape|Output tensor of same type, size as the input tensor
|===

*Quantization Parameters:*

None

*Operation Function:*

[source,c]
----
for_each (index in shape) {
    in_t value1 = tensor_read<in_t>(input1, shape, index)
    in_t acc = ~value1
    tensor_write<in_t>(output, shape, index, acc)
}
----

*Supported Data Types:*

|===
|Profile|Mode|in_t

|Any|signed 8|int8
|Any|signed 16|int16
|Any|signed 32|int32
|===

==== CEIL

Elementwise ceiling operation

*Arguments:*

|===
|Argument|Type|Name|Shape|Description

|Input|in_t*|input1|shape|Input tensor
|Output|in_t*|output|shape|Output tensor of same type, size as the input tensor
|===

*Supported Data Types:*

|===
|Profile|Mode|in_t

|MI, MT|float|float
|===

==== CLZ

Elementwise count leading zeros operation

*Arguments:*

|===
|Argument|Type|Name|Shape|Description

|Input|in_t*|input1|shape|Input tensor
|Output|in_t*|output|shape|Output tensor of same type, size as the input tensor
|===

*Operation Function:*

[source,c]
----
for_each (index in shape) {
    in_t acc = 0
    in_t value1 = tensor_read<in_t>(input1, shape, index)
    acc = count_leading_zeros(value1)
    tensor_write<in_t>(output, shape, index, acc)
}
----

*Supported Data Types:*
|===
|Profile|Mode|in_t

|Any|signed 32|int32
|===

==== EXP

Elementwise e to the x operation

*Arguments:*

|===
|Argument|Type|Name|Shape|Description

|Input|in_t*|input1|shape|Input tensor
|Output|in_t*|output|shape|Output tensor of same type, size as the input tensor
|===

*Supported Data Types:*

|===
|Profile|Mode|in_t

|MI, MT|float|float
|===

==== FLOOR

Elementwise floor operation

*Arguments:*

|===
|Argument|Type|Name|Shape|Description

|Input|in_t*|input1|shape|Input tensor
|Output|in_t*|output|shape|Output tensor of same type, size as the input tensor
|===

*Supported Data Types:*

|===
|Profile|Mode|in_t

|MI, MT|float|float
|===

==== LOG

Elementwise natural logarithm operation

*Arguments:*

|===
|Argument|Type|Name|Shape|Description

|Input|in_t*|input1|shape|Input tensor
|Output|in_t*|output|shape|Output tensor of same type, size as the input tensor
|===

*Supported Data Types:*

|===
|Profile|Mode|in_t

|MI, MT|float|float
|===

==== LOGICAL_NOT

Elementwise logical NOT of input.

*Arguments:*

|===
|Argument|Type|Name|Shape|Description

|Input|in_t*|input1|shape|Input tensor
|Output|in_t*|output|shape|Output tensor of same type, size as the input tensor
|===

*Quantization Parameters:*

None

*Operation Function:*

[source,c]
----
for_each (index in shape) {
    in_t value1 = tensor_read<in_t>(input1, shape1, index)
    in_t acc = !value1
    tensor_write<in_t>(output, shape, index, acc)
}
----

*Supported Data Types:*

|===
|Profile|Mode|in_t

|Any|bool|bool
|===

==== NEGATE

Elementwise negation operation

*Arguments:*

|===
|Argument|Type|Name|Shape|Description

|Input|in_t*|input1|shape|Input tensor
|Output|in_t*|output|shape|Output tensor of same type, size as the input tensor
|===

*Quantization Parameters:*

|===
|Argument|Type|Name|Shape|Description

|Attribute|in_t|input1_zp|-|Input 1 zero point
|Attribute|in_t|output_zp|-|Output zero point
|===

*Operation Function:*

[source,c]
----
assert(in_t == int8_t || input_zp == 0) // Zero point only for int8
assert(in_t == int8_t || output_zp == 0) // Zero point only for int8
for_each (index in shape) {
    in_t value1 = tensor_read<in_t>(input1, shape, index)
    in_t acc = appl_sub<in_t>(0, value1 - input1_zp)
    acc = apply_clip(acc, minimum<in_t>, maximum<in_t>)
    tensor_write<in_t>(output + output_zp, shape, index, acc)
}
----

*Supported Data Types:*

|===
|Profile|Mode|in_t

|Any|signed 8|int8
|Any|signed 16|int16
|Any|signed 32|int32
|MI, MT|float|float
|===

==== RECIPROCAL

Elementwise reciprocal operation. For integer operation, a TABLE should be used with the appropriate ranges.

*Arguments:*

|===
|Argument|Type|Name|Shape|Description

|Input|in_t*|input1|shape|Input tensor
|Output|in_t*|output|shape|Output tensor of same type, size as the input tensor
|===

*Supported Data Types:*

|===
|Profile|Mode|in_t

|MI, MT|float|float
|===

==== RSQRT

Elementwise reciprocal square root operation. For integer operation, a TABLE should be used with the appropriate ranges.

*Arguments:*

|===
|Argument|Type|Name|Shape|Description

|Input|in_t*|input1|shape|Input tensor
|Output|in_t*|output|shape|Output tensor of same type, size as the input tensor
|===

*Supported Data Types:*

|===
|Profile|Mode|in_t

|MI, MT|float|float
|===
